# -*- coding: utf-8 -*-
"""Cervical_Cancer (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1njSF3qkIkndYxwA4GN9gvYkQOka1f5s_
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import pearsonr
from itertools import product
from matplotlib import gridspec
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import learning_curve
from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, auc, roc_curve, roc_auc_score
from sklearn.model_selection import train_test_split

"""#**Biopsy**"""

# df_biopsy = pd.read_csv('/content/Biopsy.csv')
# df = pd.read_csv('/content/Processed_risk_factors_cervical_cancer.csv')
# df_cytolgy = pd.read_csv('/content/Citology.csv')
# df_hinselmann = pd.read_csv('/content/Hinselmann.csv')
# df_schiller = pd.read_csv('/content/Schiller.csv')

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Data/Processed_risk_factors_cervical_cancer.csv')

df.dtypes

df['Biopsy'] = df['Biopsy'].astype('category')
df['Hinselmann'] = df['Hinselmann'].astype('category')
df['Citology'] = df['Citology'].astype('category')
df['Schiller'] = df['Schiller'].astype('category')
df['Dx'] = df['Dx'].astype('bool')
df['Dx:HPV'] = df['Dx:HPV'].astype('bool')
df['Dx:CIN'] = df['Dx:CIN'].astype('bool')
df['Dx:Cancer'] = df['Dx:Cancer'].astype('bool')
df['STDs:HPV'] = df['STDs:HPV'].astype('bool')
df['STDs:Hepatitis B'] = df['STDs:Hepatitis B'].astype('bool')
df['STDs:HIV'] = df['STDs:HIV'].astype('bool')
df['STDs:AIDS'] = df['STDs:AIDS'].astype('bool')
df['STDs:molluscum contagiosum'] = df['STDs:molluscum contagiosum'].astype('bool')
df['STDs:genital herpes'] = df['STDs:genital herpes'].astype('bool')
df['STDs:pelvic inflammatory disease'] = df['STDs:pelvic inflammatory disease'].astype('bool')
df['STDs:syphilis'] = df['STDs:syphilis'].astype('bool')
df['STDs:vulvo-perineal condylomatosis'] = df['STDs:vulvo-perineal condylomatosis'].astype('bool')
df['STDs:vaginal condylomatosis'] = df['STDs:vaginal condylomatosis'].astype('bool')
df['STDs:cervical condylomatosis'] = df['STDs:cervical condylomatosis'].astype('bool')
df['STDs:condylomatosis'] = df['STDs:condylomatosis'].astype('bool')
df['STDs'] = df['STDs'].astype('bool')
df['IUD'] = df['IUD'].astype('bool')
df['Hormonal Contraceptives'] = df['Hormonal Contraceptives'].astype('bool')
df['Smokes'] = df['Smokes'].astype('bool')

df.dtypes

df.rename(columns={'Num of pregnancies':'NP', 'First sexual intercourse': 'FSI','Number of sexual partners':'NSP',  'Smokes (years)':'SY', 'Smokes (packs/year)':'SPY', 'Citology': 'Cytology',
       'Hormonal Contraceptives (years)':'HC (years)', 'IUD (years)':'IY','STDs (number)':'STDN', 'STDs: Number of diagnosis':'STDND', 'STDs: Time since first diagnosis':'TSFD', 'STDs: Time since last diagnosis':'TSLD',
       'Hormonal Contraceptives': 'HC', 'STDs:condylomatosis': 'STDC', 'STDs:vaginal condylomatosis': 'STDVC', 'STDs:vulvo-perineal condylomatosis': 'STDVPC', 'STDs:syphilis': 'STDS', 'STDs:pelvic inflammatory disease': 'STDPID',
       'STDs:genital herpes': 'STDGH', 'STDs:molluscum contagiosum': 'STDMC', 'STDs:AIDS': 'STDA',
       'STDs:HIV' : 'STDH', 'STDs:Hepatitis B': 'STDHB', 'STDs:HPV': 'STDHPV', 'STDs:cervical condylomatosis': 'STDCC',},
          inplace=True, errors='raise')

df.columns

df1 = df[['Age', 'NP', 'FSI', 'NSP', 'SY', 'SPY', 'HC (years)', 'IY', 'STDN', 'STDND', 'TSFD', 'TSLD', 'Biopsy' ,'Cytology', 'Hinselmann', 'Schiller']]
df2 = df[['Age', 'NP', 'FSI', 'NSP', 'SY', 'SPY', 'HC (years)', 'IY', 'STDN', 'STDND', 'TSFD', 'TSLD', 'Biopsy' ,'Cytology', 'Hinselmann', 'Schiller']]
def compute_corr_and_p(df1, df2):
  corrs = pd.DataFrame(index=df1.columns, columns=df2.columns, dtype=np.float64)
  pvals = corrs.copy()
  
  for i, j in product(df1.columns, df2.columns):
    corrs.loc[i,j], pvals.loc[i,j] = pearsonr(df1[i], df2[j])
  
  return corrs, pvals

def plot(corrs, pvals, siglevel=.01):
  mask = np.zeros_like(corrs, dtype=np.bool)
  mask[np.triu_indices_from(mask) | (pvals >= siglevel) ] = True

  cmap = sns.diverging_palette(220, 10, as_cmap=True)

  sns.heatmap(pvals,  cmap=cmap, center=0, square=True, linewidths=.5,
           cbar_kws={'shrink': .5}, annot=True)
cor, p = compute_corr_and_p(df1,df2)
plt.figure( figsize=(11,9))
g = sns.heatmap(p,vmin=-1, vmax=1, cmap='vlag',annot=True, annot_kws={"size":7}, fmt='.2f', linewidths=1, linecolor='w')
# plot(cor, p, 0.01)
mask = np.invert(np.tril(p<0.05))
# fig = plt.figure(figsize=(4,4))
# sns.heatmap(p, cmap="vlag", vmin=-1, vmax=1, annot=True, linewidths=1, linecolor='w')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
for text in g.texts:
    text.set_size(11)
    if text.get_text() < '0.001':
        text.set_text('<0.001')
        text.set_size(8)
        # text.set_weight('bold')

# Save a high-res copy of the image to disk
plt.tight_layout()

numeric = df[['Age', 'NSP', 'FSI', 'NP', 'SY', 'SPY', 'HC (years)', 'IY', 'STDN', 'STDND', 'TSFD', 'TSLD', 'Biopsy']]
numeric['Biopsy'] = numeric['Biopsy'].map({'Yes':1, 'No':0})

fig = plt.figure(figsize=(8,4))
sns.set_style('darkgrid')
fig.add_subplot(261)
sns.boxplot(y=numeric['Age'], color='darkorange')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
plt.xlabel('Age', weight='bold')
plt.ylabel('Years', weight='bold')
plt.tight_layout()


fig.add_subplot(262)
sns.boxplot(y=numeric['FSI'], color='darkorange')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
plt.xlabel('FSI', weight='bold')
plt.ylabel('Years', weight='bold')
plt.tight_layout()

fig.add_subplot(263)
sns.boxplot(y=numeric['NP'], color='darkorange')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
plt.xlabel('NP', weight='bold')
plt.ylabel('Number', weight='bold')
plt.tight_layout()

fig.add_subplot(264)
sns.boxplot(y=numeric['NSP'], color='darkorange')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
plt.xlabel('NSP', weight='bold')
plt.ylabel('Number', weight='bold')
plt.tight_layout()

fig.add_subplot(265)
sns.boxplot(y=numeric['HC (years)'], color='darkorange')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
plt.xlabel('HC (years)', weight='bold')
plt.ylabel('Year', weight='bold')
plt.tight_layout()

fig.add_subplot(266)
sns.boxplot(y=numeric['SPY'], color='darkorange')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
plt.xlabel('SPY', weight='bold')
plt.ylabel('Year', weight='bold')
plt.tight_layout()

fig.add_subplot(267)
sns.boxplot(y=numeric['SY'], color='darkorange')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
plt.xlabel('SY', weight='bold')
plt.ylabel('Year', weight='bold')
plt.tight_layout()

fig.add_subplot(268)
sns.boxplot(y=numeric['IY'], color='darkorange')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
plt.xlabel('IY', weight='bold')
plt.ylabel('Year', weight='bold')
plt.tight_layout()

fig.add_subplot(269)
sns.boxplot(y=numeric['STDN'], color='darkorange')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
plt.xlabel('STDN', weight='bold')
plt.ylabel('Number', weight='bold')
plt.tight_layout()

fig.add_subplot(2,6,10)
sns.boxplot(y=numeric['STDND'], color='darkorange')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
plt.xlabel('STDND', weight='bold')
plt.ylabel('Number', weight='bold')
plt.tight_layout()

fig.add_subplot(2,6,11)
sns.boxplot(y=numeric['TSFD'], color='darkorange')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
plt.xlabel('TSFD', weight='bold')
plt.ylabel('Month', weight='bold')
plt.tight_layout()

fig.add_subplot(2,6,12)
sns.boxplot(y=numeric['TSLD'], color='darkorange')
plt.xticks(weight='bold')
plt.yticks(weight='bold')
plt.xlabel('TSLD', weight='bold')
plt.ylabel('Month', weight='bold')
plt.tight_layout()

plt.tight_layout()
plt.savefig('Boxlot.png', dpi=800)
plt.savefig('Boxlot.pdf', dpi=800)

"""#**Machine Learning Analysis**"""

df

df_biopsy = df.drop(['Hinselmann', 'Schiller', 'Cytology'], axis=1)
df_biopsy = pd.DataFrame(df_biopsy)
df_cytolgy = df.drop(['Hinselmann', 'Schiller', 'Biopsy'], axis=1)
df_cytolgy = pd.DataFrame(df_cytolgy)
df_schiller = df.drop(['Hinselmann', 'Cytology', 'Biopsy'], axis=1)
df_schiller = pd.DataFrame(df_schiller)
df_hinselmann = df.drop(['Schiller', 'Cytology', 'Biopsy'], axis=1)
df_hinselmann = pd.DataFrame(df_hinselmann)

"""**Biopsy**"""

X = df_biopsy.drop(['Biopsy'], axis=1)
y = df_biopsy.Biopsy

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, matthews_corrcoef, cohen_kappa_score
rf = RandomForestClassifier(n_estimators=10)
rf.fit(X_train, y_train)
acc = rf.score(X_test, y_test)
y_pred = rf.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
kapp = cohen_kappa_score(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))
print('mcc: '+ str(mcc))
print('kapp: '+ str(kapp))

rfFeatureImportance = pd.Series(rf.feature_importances_,index=X.columns).sort_values(ascending=False)

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
xg = XGBClassifier(learning_rate=0.60)
xg.fit(X_train, y_train)
acc = xg.score(X_test, y_test)
y_pred = xg.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
acc = dt.score(X_test, y_test)
y_pred = dt.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, matthews_corrcoef, cohen_kappa_score
mlp = MLPClassifier(hidden_layer_sizes=5)
mlp.fit(X_train, y_train)
acc = mlp.score(X_test, y_test)
y_pred = mlp.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
kapp = cohen_kappa_score(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))
print('mcc: '+ str(mcc))
print('kapp: '+ str(kapp))

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, matthews_corrcoef, cohen_kappa_score
lr = LogisticRegression()
lr.fit(X_train, y_train)
acc = lr.score(X_test, y_test)
y_pred = lr.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
kapp = cohen_kappa_score(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))
print('mcc: '+ str(mcc))
print('kapp: '+ str(kapp))

"""**Cytology**"""

X = df_cytolgy.drop(['Cytology'], axis=1)
y = df_cytolgy.Cytology

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, matthews_corrcoef, cohen_kappa_score
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
acc = rf.score(X_test, y_test)
y_pred = rf.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
kapp = cohen_kappa_score(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))
print('mcc: '+ str(mcc))
print('kapp: '+ str(kapp))

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
xg = XGBClassifier()
xg.fit(X_train, y_train)
acc = xg.score(X_test, y_test)
y_pred = xg.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

xgFeatureImportance = pd.Series(xg.feature_importances_,index=X.columns).sort_values(ascending=False)

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss
# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
acc = dt.score(X_test, y_test)
y_pred = dt.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, matthews_corrcoef, cohen_kappa_score
mlp = MLPClassifier(hidden_layer_sizes=5)
mlp.fit(X_train, y_train)
acc = mlp.score(X_test, y_test)
y_pred = mlp.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
kapp = cohen_kappa_score(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, matthews_corrcoef, cohen_kappa_score
lr = LogisticRegression()
lr.fit(X_train, y_train)
acc = lr.score(X_test, y_test)
y_pred = lr.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
kapp = cohen_kappa_score(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

"""**Hinselmann**"""

X = df_hinselmann.drop(['Hinselmann'], axis=1)
y = df_hinselmann.Hinselmann
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, matthews_corrcoef, cohen_kappa_score
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
acc = rf.score(X_test, y_test)
y_pred = rf.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
kapp = cohen_kappa_score(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))
print('mcc: '+ str(mcc))
print('kapp: '+ str(kapp))

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
hxg = XGBClassifier()
hxg.fit(X_train, y_train)
acc = xg.score(X_test, y_test)
y_pred = xg.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

hxgFeatureImportance = pd.Series(hxg.feature_importances_,index=X.columns).sort_values(ascending=False)

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss
# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
acc = dt.score(X_test, y_test)
y_pred = dt.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, matthews_corrcoef, cohen_kappa_score
mlp = MLPClassifier(hidden_layer_sizes=5)
mlp.fit(X_train, y_train)
acc = mlp.score(X_test, y_test)
y_pred = mlp.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
kapp = cohen_kappa_score(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))
print('mcc: '+ str(mcc))
print('kapp: '+ str(kapp))

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, matthews_corrcoef, cohen_kappa_score
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
lr = LogisticRegression()
lr.fit(X_train, y_train)
acc = lr.score(X_test, y_test)
y_pred = lr.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
kapp = cohen_kappa_score(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

"""**Schiller**"""

X = df_schiller.drop(['Schiller'], axis=1)
y = df_schiller.Schiller
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, matthews_corrcoef, cohen_kappa_score
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
acc = rf.score(X_test, y_test)
y_pred = rf.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
kapp = cohen_kappa_score(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
sxg = XGBClassifier()
sxg.fit(X_train, y_train)
acc = xg.score(X_test, y_test)
y_pred = xg.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

sxgFeatureImportance = pd.Series(sxg.feature_importances_,index=X.columns).sort_values(ascending=False)

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
acc = dt.score(X_test, y_test)
y_pred = dt.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, matthews_corrcoef, cohen_kappa_score
mlp = MLPClassifier(hidden_layer_sizes=5)
mlp.fit(X_train, y_train)
acc = mlp.score(X_test, y_test)
y_pred = mlp.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
kapp = cohen_kappa_score(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))

from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, matthews_corrcoef, cohen_kappa_score
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
lr = LogisticRegression()
lr.fit(X_train, y_train)
acc = lr.score(X_test, y_test)
y_pred = lr.predict(X_test)
f1 = f1_score(y_test, y_pred, average='micro')
precision_score = precision_score(y_test, y_pred, average='micro')
recall_score = recall_score(y_test, y_pred, average='micro')
log_loss = log_loss(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
kapp = cohen_kappa_score(y_test, y_pred)
print('Accuracy: '+ str(acc))
print('f1: '+ str(f1))
print('precision_score: '+ str(precision_score))
print('recall_score: '+ str(recall_score))
print('log_loss: '+ str(log_loss))
print('mcc: '+ str(mcc))
print('kapp: '+ str(kapp))

fig = plt.figure(figsize=(10, 12))
sns.set_style('darkgrid')
sns.set_palette("Paired")

ax1 = fig.add_subplot(2, 2, 1)
sns.set_palette("Paired")
sns.barplot(x = rfFeatureImportance, y= rfFeatureImportance.index )

plt.title('(A)', weight='bold')
plt.xlabel('Feature Importance Score', weight='bold')
plt.ylabel('Features', weight='bold')

ax2 = fig.add_subplot(2, 2, 2)
sns.barplot(x = xgFeatureImportance, y= xgFeatureImportance.index )
plt.title('(B)', weight='bold')
plt.xlabel('Feature Importance Score', weight='bold')
plt.ylabel('Features', weight='bold')

ax3 = fig.add_subplot(2, 2, 3)
sns.barplot(x = hxgFeatureImportance, y= hxgFeatureImportance.index )
plt.title('(C)', weight='bold')
plt.xlabel('Feature Importance Score', weight='bold')
plt.ylabel('Features', weight='bold')

ax4 = fig.add_subplot(2, 2, 4)
sns.barplot(x = sxgFeatureImportance, y= sxgFeatureImportance.index )
plt.title('(D)', weight='bold')
plt.xlabel('Feature Importance Score', weight='bold')
plt.ylabel('Features', weight='bold')

plt.tight_layout()
plt.savefig('risk.png', dpi=800)
plt.savefig('risk.pdf', dpi=800)
plt.show()